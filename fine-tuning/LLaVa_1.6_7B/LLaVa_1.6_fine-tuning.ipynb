{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib -q -U\n",
    "!pip install datasets -q -U\n",
    "!pip install -q bitsandbytes sentencepiece  accelerate loralib\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install hf_transfer -q -U\n",
    "!pip install pickleshare -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows for faster downloads\n",
    "%env HF_HUB_ENABLE_HF_TRANSFER=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klone nach 'LLaVA'...\n",
      "remote: Enumerating objects: 2297, done.\u001b[K\n",
      "remote: Total 2297 (delta 0), reused 0 (delta 0), pack-reused 2297 (from 1)\u001b[K\n",
      "Empfange Objekte: 100% (2297/2297), 13.71 MiB | 12.02 MiB/s, fertig.\n",
      "LÃ¶se Unterschiede auf: 100% (1405/1405), fertig.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir('LLaVA'):\n",
    "    !git clone https://github.com/haotian-liu/LLaVA.git\n",
    "else:\n",
    "    print(\"LLaVA already exists. Skipping clone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File modified successfully.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the path to the builder.py file\n",
    "file_path = '/Users/fabian.fuerst/Documents/GitHub/Fine-tuned-LLaVA-Vision-and-Language/fine-tuning/LLaVa_1.6_7B/LLaVA/llava/model/builder.py'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Regular expression to find the block between 'vision_tower = model.get_vision_tower()' and 'vision_tower.image_processor'\n",
    "pattern_block = (\n",
    "    r'(vision_tower = model.get_vision_tower\\(\\)\\n)'\n",
    "    r'.*?' # Non-greedy match for any characters\n",
    "    r'(image_processor = vision_tower.image_processor)'\n",
    ")\n",
    "\n",
    "replacement_block = (\n",
    "    r'\\1' # Keep the first line unchanged\n",
    "    '       if not vision_tower.is_loaded:\\n'\n",
    "    '           print(\\'vision_tower is not loades so loading now\\')\\n'\n",
    "    '           vision_tower.load_model(device_map=device_map)\\n'\n",
    "    '           vision_tower.to(device=device_map, dtype=torch.bfloat16)\\n'\n",
    "    '       else:\\n'\n",
    "    '           print(\\'vision_tower is already loaded\\')\\n'\n",
    "    r'      \\2' # Keep the last line unchanged\n",
    ")\n",
    "\n",
    "# Replace the specific block\n",
    "content = re.sub(pattern_block, replacement_block, content, flags=re.DOTALL)\n",
    "\n",
    "# Write the content back to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    file.write(content)\n",
    "\n",
    "print('File modified successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No modification needed.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the path to the builder.py file\n",
    "file_path = '/Users/fabian.fuerst/Documents/GitHub/Fine-tuned-LLaVA-Vision-and-Language/fine-tuning/LLaVa_1.6_7B/LLaVA/llava/model/builder.py'\n",
    "\n",
    "# Read the content of the file\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Regular expression to find 'float16' and replace it with 'bfloat16'\n",
    "pattern = r'(?<!b)float16'\n",
    "\n",
    "# CHeck if there are any matches\n",
    "if re.search(pattern, content):\n",
    "    # Replace all matches\n",
    "    modified_content = re.sub(pattern, 'bfloat16', content)\n",
    "\n",
    "    # Write the content back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "\n",
    "    print('File modified successfully.')\n",
    "else:\n",
    "    print('No modification needed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fabian.fuerst/Documents/GitHub/Fine-tuned-LLaVA-Vision-and-Language/fine-tuning/LLaVa_1.6_7B/LLaVA\n"
     ]
    }
   ],
   "source": [
    "%cd LLaVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Takes quite a while to run\n",
    "!pip install -e . -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install protobuf -q -U\n",
    "!pip installl --upgrade Pillow -q\n",
    "!pip install -e '.[train]' -q\n",
    "!pip install flash-attn --no-build-isolation -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from PIL import Image\n",
    "import transformers\n",
    "from transformers import AutoProcessor, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.mm_utils import get_model_name_from_path\n",
    "from llava.eval.run_llava import eval_model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
